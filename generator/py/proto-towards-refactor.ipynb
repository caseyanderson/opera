{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "49c691aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "import argparse\n",
    "\n",
    "class Opera:\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        \"\"\" make a ghostses object\n",
    "            read the corpus into object\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        f = open(str(self.filename), 'r')\n",
    "        self.corpus = f.read() # plaintext of the corpus\n",
    "\n",
    "\n",
    "    def getSentences(self):\n",
    "        \"\"\" tokenize corpus by sentence \"\"\"\n",
    "        self.sentences = sent_tokenize(score.corpus)        \n",
    "\n",
    "    \n",
    "    def getWords(self, preserveSpaces = True):\n",
    "        \"\"\" tokenize corpus sentences by word \"\"\"\n",
    "        self.words = []\n",
    "        for sentence in self.sentences:\n",
    "            if preserveSpaces == True:\n",
    "                words = [[word_tokenize(w), ' '] for w in sentence.split()]\n",
    "                wordList = list(itertools.chain(*list(itertools.chain(*words))))\n",
    "                if wordList[-1] == ' ':\n",
    "                    # removes trailing whitespace @ end of sentence if there is any\n",
    "                    wordList.pop()\n",
    "                self.words.append(wordList)\n",
    "            if preserveSpaces == False:\n",
    "                words = word_tokenize(sentence)\n",
    "                self.words.append(words)\n",
    "        self.preserveSpaces = preserveSpaces\n",
    "    \n",
    "    def getPOS(self):\n",
    "        \"\"\" parts of speech analysis\n",
    "            TODO:\n",
    "                1. if preserveSpaces\n",
    "        \"\"\"\n",
    "        self.processedCorpus = []\n",
    "        \n",
    "        if self.preserveSpaces == False:\n",
    "            print(\"removing spaces\")\n",
    "        elif self.preserveSpaces == True:\n",
    "            # print(\"preserving spaces\")\n",
    "            sentenceStep = 0\n",
    "            processedSentences = []\n",
    "            for sentence in self.sentences:\n",
    "                tokenizedSentence = word_tokenize(sentence)\n",
    "                posSentence = pos_tag(tokenizedSentence)                \n",
    "                processedSentence = []\n",
    "                for word in self.words[sentenceStep]:\n",
    "                    if word.isspace() == False:\n",
    "                        posWord = list(posSentence.pop(0))\n",
    "                        processedSentence.append([posWord[0], {\"pos\": posWord[1]}])\n",
    "                    elif word.isspace() == True:\n",
    "                        processedSentence.append(word)\n",
    "                self.processedCorpus.append(processedSentence)\n",
    "                sentenceStep+=1\n",
    "                # print(\"~~~ no more words in sentence ~~~\")\n",
    "            # print(\"*** no more sentences in corpus ***\")\n",
    "            # print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "8d629648",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = Opera(\"corpora/Stein-short.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "ebb30343",
   "metadata": {},
   "outputs": [],
   "source": [
    "score.getSentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "a9562341",
   "metadata": {},
   "outputs": [],
   "source": [
    "score.getWords(preserveSpaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "11e8ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score.getPOS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "97151710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( score.processedCorpus )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "fe1ddc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "TODO\n",
    "    1. make a self.processedCorpus, a list with spaces and a dictionary for every word\n",
    "    2. make a function that ingests class member variables into self.processedCorpus\n",
    "\n",
    "'''\n",
    "\n",
    "processedCorpus = []\n",
    "sentenceStep = 0\n",
    "\n",
    "for sentence in score.pos:\n",
    "    processedSentence = []\n",
    "    for item in sentence:\n",
    "        if type(item) == tuple:\n",
    "            listItem = list(item)\n",
    "            processedSentence.append([listItem[0], {\"pos\": listItem[1]}])\n",
    "        else:\n",
    "            processedSentence.append(item)\n",
    "    processedCorpus.append(processedSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b89669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
